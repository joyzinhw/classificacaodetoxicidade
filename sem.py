# ===========================
# Imports
# ===========================
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, RandomizedSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import (accuracy_score, precision_score, recall_score,
                             f1_score, roc_auc_score, matthews_corrcoef,
                             confusion_matrix, classification_report)
from rdkit import Chem
from rdkit.Chem import AllChem, DataStructs
import matplotlib.pyplot as plt
import seaborn as sns

from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
from catboost import CatBoostClassifier

# ===========================
# 1. Carregar Dataset
# ===========================
df = pd.read_csv('dataset_final.csv')

# Converter SMILES em fingerprints
def smiles_to_fingerprint(smiles, radius=2, n_bits=1024):
    mol = Chem.MolFromSmiles(smiles)
    if mol is None:
        return None
    fp = AllChem.GetMorganFingerprintAsBitVect(mol, radius=radius, nBits=n_bits)
    arr = np.zeros((n_bits,), dtype=np.int32)
    DataStructs.ConvertToNumpyArray(fp, arr)
    return arr

X = np.array([smiles_to_fingerprint(sm) for sm in df['SMILES']])
y = df['label'].values

# Remover entradas inv√°lidas
valid_indices = [i for i, x in enumerate(X) if x is not None]
X = np.array([X[i] for i in valid_indices])
y = y[valid_indices]

# ===========================
# 2. Split e Escalonamento
# ===========================
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y)

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

print("Distribui√ß√£o de classes no treino:", np.bincount(y_train))

# ===========================
# 3. Modelos + Otimiza√ß√£o
# ===========================
models = {
    'Random Forest': RandomForestClassifier(random_state=42),
    'SVM': SVC(probability=True, random_state=42),
    'MLP': MLPClassifier(max_iter=500, random_state=42),
    'XGBoost': XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss'),
    'LightGBM': LGBMClassifier(random_state=42),
    'CatBoost': CatBoostClassifier(verbose=0, random_state=42)
}

param_grid = {
    'Random Forest': {
        'n_estimators': [100, 200],
        'max_depth': [None, 10, 20],
        'min_samples_split': [2, 5]
    },
    'SVM': {
        'C': [0.1, 1, 10],
        'gamma': ['scale', 'auto'],
        'kernel': ['rbf', 'poly']
    },
    'MLP': {
        'hidden_layer_sizes': [(100,), (100,50)],
        'alpha': [0.0001, 0.001],
        'activation': ['relu', 'tanh']
    },
    'XGBoost': {
        'n_estimators': [100, 200],
        'max_depth': [3, 6],
        'learning_rate': [0.01, 0.1]
    },
    'LightGBM': {
        'n_estimators': [100, 200],
        'max_depth': [-1, 10],
        'learning_rate': [0.01, 0.1]
    },
    'CatBoost': {
        'iterations': [100, 200],
        'depth': [4, 6],
        'learning_rate': [0.01, 0.1]
    }
}

# ===========================
# 4. Fun√ß√£o de Avalia√ß√£o (retorna m√©tricas)
# ===========================
def evaluate_model(model, X_test, y_test, name):
    y_pred = model.predict(X_test)
    y_proba = model.predict_proba(X_test)[:, 1]

    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    auc = roc_auc_score(y_test, y_proba)
    mcc = matthews_corrcoef(y_test, y_pred)

    print(f"\n=== {name} ===")
    print(f"Acur√°cia: {accuracy:.4f}")
    print(f"Precis√£o: {precision:.4f}")
    print(f"Recall: {recall:.4f}")
    print(f"F1-score: {f1:.4f}")
    print(f"AUC-ROC: {auc:.4f}")
    print(f"MCC: {mcc:.4f}")
    print("\nRelat√≥rio de Classifica√ß√£o:")
    print(classification_report(y_test, y_pred, target_names=['N√£o T√≥xico', 'T√≥xico']))

    cm = confusion_matrix(y_test, y_pred)
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=['N√£o T√≥xico', 'T√≥xico'],
                yticklabels=['N√£o T√≥xico', 'T√≥xico'])
    plt.title(f'Matriz de Confus√£o - {name}')
    plt.ylabel('Verdadeiro')
    plt.xlabel('Predito')
    plt.show()

    return {
        'Modelo': name,
        'Acur√°cia': accuracy,
        'Precis√£o': precision,
        'Recall': recall,
        'F1-score': f1,
        'AUC-ROC': auc,
        'MCC': mcc
    }

# ===========================
# 5. Treinar, Avaliar e armazenar resultados
# ===========================
results = []

for name, model in models.items():
    print(f'\nüîç Otimizando {name}...')
    search = RandomizedSearchCV(model, param_distributions=param_grid[name],
                                n_iter=5, cv=3, scoring='f1', random_state=42, n_jobs=-1)
    search.fit(X_train, y_train)
    best_model = search.best_estimator_
    metrics = evaluate_model(best_model, X_test, y_test, name)
    results.append(metrics)

# ===========================
# 6. Compara√ß√£o Final entre Modelos
# ===========================
results_df = pd.DataFrame(results)
print("\n=== Compara√ß√£o entre modelos ===")
print(results_df.sort_values(by='F1-score', ascending=False))

# Gr√°fico comparativo das m√©tricas F1, AUC-ROC e MCC
plt.figure(figsize=(12, 6))
sns.barplot(data=results_df.melt(id_vars='Modelo', value_vars=['F1-score', 'AUC-ROC', 'MCC']),
            x='Modelo', y='value', hue='variable')
plt.title('Compara√ß√£o de M√©tricas entre Modelos')
plt.ylabel('Valor da M√©trica')
plt.xticks(rotation=45)
plt.legend(title='M√©trica')
plt.show()
